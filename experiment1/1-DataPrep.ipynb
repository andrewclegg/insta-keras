{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook contains preprocessing steps that need to be run before the [Model Training](2-ModelTraining.ipynb) notebook.\n",
    "\n",
    "The objective is to minimize the amount of data processing that the model trainer needs to do on loading each batch from disk, because we don't want to introduce an IO or CPU bottleneck that will slow down the whole training process.\n",
    "\n",
    "So, the data will be written out to disk in a form that's as close as possible to the input format needed by the model.\n",
    "\n",
    "Also, we'll store this data on an SSD volume because we need random access to it. Seek times on a spinning disk are a showstopper for this.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You first need to download the data files for the [Kaggle Instacart challenge](https://www.kaggle.com/c/instacart-market-basket-analysis) and unpack them into a directory called `../csv` (relative to this notebook).\n",
    "\n",
    "After that we're going to read and parse the CSV files into Pandas dataframes, perform some joining and filtering, extract raw Numpy arrays and write them back out to disk into a directory called `h5`. The model trainer will then read them from there. Make sure that `h5` resides on an SSD (see above).\n",
    "\n",
    "## RAM usage\n",
    "\n",
    "Beware! This notebook requires around 7GB of RAM to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import shutil\n",
    "import os\n",
    "from itertools import *\n",
    "from collections import defaultdict\n",
    "\n",
    "csv_dir = '../csv/'\n",
    "h5_dir = 'h5/'\n",
    "\n",
    "path = os.path.join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV parsing\n",
    "\n",
    "First read the CSV files into Pandas. See the competition website for descriptions of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order_products_prior = pd.read_csv(path(csv_dir, 'order_products__prior.csv'), engine='c',\n",
    "                                   dtype={'order_id':np.int32, \n",
    "                                          'product_id':np.int32, \n",
    "                                          'add_to_cart_order':np.int8, \n",
    "                                          'reordered':np.int8})\n",
    "\n",
    "order_products_train = pd.read_csv(path(csv_dir, 'order_products__train.csv'), engine='c',\n",
    "                                   dtype={'order_id':np.int32, \n",
    "                                          'product_id':np.int32, \n",
    "                                          'add_to_cart_order':np.int8, \n",
    "                                          'reordered':np.int8})\n",
    "\n",
    "orders = pd.read_csv(path(csv_dir, 'orders.csv'), engine='c',\n",
    "                     dtype={'order_id':np.int32,\n",
    "                            'user_id':np.int32,\n",
    "                            'order_number':np.int8,\n",
    "                            'order_dow':np.int8,\n",
    "                            'order_hour_of_day':np.int8\n",
    "                           })\n",
    "\n",
    "products = pd.read_csv(path(csv_dir, 'products.csv'), engine='c',\n",
    "                       dtype={'product_id':np.int32,\n",
    "                              'aisle_id':np.int8,\n",
    "                              'department_id':np.int8\n",
    "                             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Now we need to process the data to:\n",
    "\n",
    "* Count the number of users and products, and the size of the biggest order\n",
    " * The model needs to know how big to make its inputs and embedding tables\n",
    "* Filter out each user's first order, for now\n",
    " * None of the items in those are reorders (by definition) so they make things harder for the model\n",
    " * NB this means we can't make predictions based on just one order, which is a tradeoff worth revisiting later\n",
    "* Retrieve pairs of consecutive order IDs for the same user\n",
    " * We're trying to predict the reorders in the second from the contents of the first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49688"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_product_id = max(products.product_id)\n",
    "max_product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206209"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_user_id = max(orders.user_id)\n",
    "max_user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`order_products` tells us what products were present in each order, and which of those were reorders. It also contains an `add_to_cart_order` column that we're ignoring for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>49683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  product_id  reordered\n",
       "0         1       49302          1\n",
       "1         1       11109          1\n",
       "2         1       10246          0\n",
       "3         1       49683          0\n",
       "4         1       43633          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_products = pd.concat([order_products_train, order_products_prior], axis=0\n",
    "                          )[['order_id', 'product_id', 'reordered']]\n",
    "order_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`return_orders` are all orders which were _not_ that user's first order. Then we join these onto `order_products`. The `orders` table also contains some other columns that we're not using, e.g. time-related data, so we'll drop these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2398795</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473747</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2254736</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>431534</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3367565</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  user_id  order_number\n",
       "1   2398795        1             2\n",
       "2    473747        1             3\n",
       "3   2254736        1             4\n",
       "4    431534        1             5\n",
       "5   3367565        1             6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_orders = orders.query('order_number > 1'\n",
    "                            )[['order_id', 'user_id', 'order_number']]\n",
    "return_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2398795</th>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398795</th>\n",
       "      <td>10258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398795</th>\n",
       "      <td>12427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398795</th>\n",
       "      <td>13176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398795</th>\n",
       "      <td>26088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          product_id  reordered\n",
       "order_id                       \n",
       "2398795          196          1\n",
       "2398795        10258          0\n",
       "2398795        12427          1\n",
       "2398795        13176          0\n",
       "2398795        26088          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_order_products = pd.merge(left=return_orders[['order_id']],\n",
    "                                 right=order_products,\n",
    "                                 on='order_id'\n",
    "                                ).set_index('order_id')\n",
    "return_order_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create two new data structures:\n",
    "\n",
    "`order_sets` maps from order ID to the set of product IDs that were present in that order.\n",
    "\n",
    "`reorder_sets` is the same, but only includes those which were reordered (i.e. the user had ordered them before at some point). This is indicated by a flag in `order_products` so we don't have to reconstruct the user's entire history to determine this, thankfully.\n",
    "\n",
    "This will take a few minutes to run. But first, clear out some tables we don't need any more, to save RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del order_products_prior\n",
    "del order_products_train\n",
    "del order_products\n",
    "del orders\n",
    "del products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3139874, 2948968)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It might be much quicker to use numpy arrays here, and to rewrite\n",
    "#Â the loop to group by the index values (i.e the order IDs) first\n",
    "\n",
    "order_sets = defaultdict(set)\n",
    "reorder_sets = defaultdict(set)\n",
    "\n",
    "for row in return_order_products.itertuples():\n",
    "  order_sets[row.Index].add(row.product_id)\n",
    "  if row.reordered == 1:\n",
    "    reorder_sets[row.Index].add(row.product_id)\n",
    "\n",
    "(len(order_sets), len(reorder_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biggest_order_size = max(len(order) for order in order_sets.values())\n",
    "biggest_order_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to generate the order pairs for each user. This will also take a few minutes.\n",
    "\n",
    "Some of the later orders will be in the Kaggle test set, which we're not using for this project (as our objective is slightly different from the Kaggle contest). So we filter down to only ones that we have data for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>2398795</td>\n",
       "      <td>473747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>473747</td>\n",
       "      <td>2254736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2254736</td>\n",
       "      <td>431534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>431534</td>\n",
       "      <td>3367565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3367565</td>\n",
       "      <td>550135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x        y\n",
       "user_id                    \n",
       "1       0  2398795   473747\n",
       "        1   473747  2254736\n",
       "        2  2254736   431534\n",
       "        3   431534  3367565\n",
       "        4  3367565   550135"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the itertools docs -- get consecutive pairs from a sequence\n",
    "def pairwise(iterable):\n",
    "  \"s -> (s0, s1), (s1, s2), (s2, s3), ...\"\n",
    "  a, b = tee(iterable)\n",
    "  next(b, None)\n",
    "  return izip(a, b)\n",
    "\n",
    "def make_x_y(order_ids):\n",
    "  pairs = list(pairwise(order_ids))\n",
    "  return pd.DataFrame.from_records(pairs, columns=['x', 'y'])\n",
    "\n",
    "valid = return_orders[return_orders.order_id.isin(return_order_products.index)]\n",
    "sort_cols = ['user_id', 'order_number']\n",
    "order_pairs = valid.sort_values(sort_cols).groupby(['user_id']).order_id.apply(make_x_y)\n",
    "order_pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate output data\n",
    "\n",
    "Now we write the data out to disk in HDF5 format. This also takes quite some time.\n",
    "\n",
    "The `order_sets` and `reorder_sets` are converted to zero-padded arrays, each as long as the biggest order, so we don't have to do that at training time. This is fine because there is no product ID 0. When training the model, Keras will filter out and ignore the zeros.\n",
    "\n",
    "Do some more cleanup first though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del return_orders\n",
    "del return_order_products\n",
    "del valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u8 = np.dtype('uint8')\n",
    "u16 = np.dtype('uint16')\n",
    "u32 = np.dtype('uint32')\n",
    "vu8 = h5py.special_dtype(vlen=u8)\n",
    "vu16 = h5py.special_dtype(vlen=u16)\n",
    "\n",
    "datapath = path(h5_dir, 'training_data.h5')\n",
    "\n",
    "try:\n",
    "  os.remove(datapath)\n",
    "except Exception, e:\n",
    "  print(\"Couldn't remove %s: %s\" % (datapath, str(e)))\n",
    "\n",
    "datafile = h5py.File(datapath)\n",
    "num_rows = len(order_pairs)\n",
    "orders_dataset = datafile.create_dataset('orders', (num_rows, biggest_order_size), dtype=u16)\n",
    "reorders_dataset = datafile.create_dataset('reorders', (num_rows, biggest_order_size), dtype=u16)\n",
    "users_dataset = datafile.create_dataset('users', (num_rows,), dtype=u32)\n",
    "items_dataset = datafile.create_dataset('items', (num_rows,), dtype=vu16)\n",
    "labels_dataset = datafile.create_dataset('labels', (num_rows,), dtype=vu8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote row 0 of 2933665\n",
      "Wrote row 100000 of 2933665\n",
      "Wrote row 200000 of 2933665\n",
      "Wrote row 300000 of 2933665\n",
      "Wrote row 400000 of 2933665\n",
      "Wrote row 500000 of 2933665\n",
      "Wrote row 600000 of 2933665\n",
      "Wrote row 700000 of 2933665\n",
      "Wrote row 800000 of 2933665\n",
      "Wrote row 900000 of 2933665\n",
      "Wrote row 1000000 of 2933665\n",
      "Wrote row 1100000 of 2933665\n",
      "Wrote row 1200000 of 2933665\n",
      "Wrote row 1300000 of 2933665\n",
      "Wrote row 1400000 of 2933665\n",
      "Wrote row 1500000 of 2933665\n",
      "Wrote row 1600000 of 2933665\n",
      "Wrote row 1700000 of 2933665\n",
      "Wrote row 1800000 of 2933665\n",
      "Wrote row 1900000 of 2933665\n",
      "Wrote row 2000000 of 2933665\n",
      "Wrote row 2100000 of 2933665\n",
      "Wrote row 2200000 of 2933665\n",
      "Wrote row 2300000 of 2933665\n",
      "Wrote row 2400000 of 2933665\n",
      "Wrote row 2500000 of 2933665\n",
      "Wrote row 2600000 of 2933665\n",
      "Wrote row 2700000 of 2933665\n",
      "Wrote row 2800000 of 2933665\n",
      "Wrote row 2900000 of 2933665\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(num_rows):\n",
    "  \n",
    "  user_id = order_pairs.index[i][0]\n",
    "  \n",
    "  # The earlier of the two orders\n",
    "  order1 = order_pairs.iloc[i, 0]\n",
    "\n",
    "  # The later of the two orders, that we're trying to predict the contents of\n",
    "  order2 = order_pairs.iloc[i, 1]\n",
    "  \n",
    "  # Create padded array from order1's order set\n",
    "  order1_padded = np.zeros(biggest_order_size, dtype=np.uint16)\n",
    "  order1_set = list(order_sets[order1])\n",
    "  order1_padded[0:len(order1_set)] = order1_set\n",
    "  \n",
    "  # Create padded array from reorder set -- might not be one, some orders have no reorders\n",
    "  reorder_padded = np.zeros_like(order1_padded)\n",
    "  if order1 in reorder_sets:\n",
    "    reorder_set = list(reorder_sets[order1])\n",
    "    reorder_padded[0:len(reorder_set)] = reorder_set\n",
    "\n",
    "  # Labels for each item in order1:\n",
    "  # 1 if item is in next order, 0 otherwise\n",
    "  order2_set = order_sets[order2]\n",
    "  labels = np.array([1 if item in order2_set else 0 for item in order1_set])\n",
    "  \n",
    "  # Write data out to file\n",
    "  orders_dataset[i] = order1_padded\n",
    "  reorders_dataset[i] = reorder_padded\n",
    "  users_dataset[i] = user_id\n",
    "  items_dataset[i] = order1_set\n",
    "  labels_dataset[i] = labels\n",
    "  if i % 100000 == 0:\n",
    "    print(\"Wrote row %d of %d\" % (i, num_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can write out some scalar values that the model needs to know, and then close the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biggest_order_scalar = datafile.create_dataset('biggest_order_size', (1,), dtype=u16)\n",
    "num_rows_scalar = datafile.create_dataset('num_rows', (1,), dtype=u32)\n",
    "max_product_id_scalar = datafile.create_dataset('max_product_id', (1,), dtype=u16)\n",
    "max_user_id_scalar = datafile.create_dataset('max_user_id', (1,), dtype=u32)\n",
    "biggest_order_scalar[0] = biggest_order_size\n",
    "num_rows_scalar[0] = num_rows\n",
    "max_product_id_scalar[0] = max_product_id\n",
    "max_user_id_scalar[0] = max_user_id\n",
    "datafile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
