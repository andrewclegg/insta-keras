{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook contains preprocessing steps that need to be run before the [Model Training](2-ModelTraining.ipynb) notebook.\n",
    "\n",
    "The objective is to minimize the amount of data processing that the model trainer needs to do before training on each batch, because we don't want to introduce an IO or CPU bottleneck that will slow down the whole training process.\n",
    "\n",
    "So, the data will be written out to disk in a form that's as close as possible to the input format needed by the model. **If possible** you should use an SSD because it'll be pretty slow otherwise. (It's still _quite_ slow even with a local SSD...)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You first need to download the data files for the [Kaggle Instacart challenge](https://www.kaggle.com/c/instacart-market-basket-analysis) and unpack them into a directory called `../csv` (relative to this notebook).\n",
    "\n",
    "After that we're going to read and parse the CSV files into Pandas dataframes, perform some joining and filtering, extract raw Numpy arrays and write them back out to disk into a directory called `h5`. The model trainer will then read them from there.\n",
    "\n",
    "## RAM usage\n",
    "\n",
    "Beware! This notebook requires around 4GB of RAM to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import shutil\n",
    "import os\n",
    "from itertools import *\n",
    "from collections import defaultdict\n",
    "\n",
    "csv_dir = '../csv/'\n",
    "h5_dir = 'h5/'\n",
    "\n",
    "path = os.path.join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV parsing\n",
    "\n",
    "First read the CSV files into Pandas. See the competition website for descriptions of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order_products_prior = pd.read_csv(path(csv_dir, 'order_products__prior.csv'), engine='c',\n",
    "                                   dtype={'order_id':np.int32, \n",
    "                                          'product_id':np.int32, \n",
    "                                          'add_to_cart_order':np.int8, \n",
    "                                          'reordered':np.int8})\n",
    "\n",
    "order_products_train = pd.read_csv(path(csv_dir, 'order_products__train.csv'), engine='c',\n",
    "                                   dtype={'order_id':np.int32, \n",
    "                                          'product_id':np.int32, \n",
    "                                          'add_to_cart_order':np.int8, \n",
    "                                          'reordered':np.int8})\n",
    "\n",
    "orders = pd.read_csv(path(csv_dir, 'orders.csv'), engine='c',\n",
    "                     dtype={'order_id':np.int32,\n",
    "                            'user_id':np.int32,\n",
    "                            'order_number':np.int8,\n",
    "                            'order_dow':np.int8,\n",
    "                            'order_hour_of_day':np.int8\n",
    "                           })\n",
    "\n",
    "products = pd.read_csv(path(csv_dir, 'products.csv'), engine='c',\n",
    "                       dtype={'product_id':np.int32,\n",
    "                              'aisle_id':np.int8,\n",
    "                              'department_id':np.int8\n",
    "                             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Now we need to process the data to:\n",
    "\n",
    "* Count the number of users and products, and the size of the biggest order\n",
    " * The model needs to know how big to make its inputs and embedding tables\n",
    "* Filter out each user's first order, for now\n",
    " * None of the items in those are reorders (by definition) so they make things harder for the model\n",
    " * NB this means we can't make predictions based on just one order, which is a tradeoff worth revisiting later\n",
    "* Retrieve pairs of consecutive order IDs for the same user\n",
    " * We're trying to predict the reorders in the second from the contents of the first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49688"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_product_id = max(products.product_id)\n",
    "max_product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206209"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_user_id = max(orders.user_id)\n",
    "max_user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`order_products` tells us what products were present in each order, and which of those were reorders. It also contains an `add_to_cart_order` column that we're ignoring for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>49683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  product_id  reordered\n",
       "0         1       49302          1\n",
       "1         1       11109          1\n",
       "2         1       10246          0\n",
       "3         1       49683          0\n",
       "4         1       43633          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_products = pd.concat([order_products_train, order_products_prior], axis=0\n",
    "                          )[['order_id', 'product_id', 'reordered']]\n",
    "order_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`return_orders` are all orders which were _not_ that user's first order. Then we join these onto `order_products`. The `orders` table also contains some other columns that we're not using, e.g. time-related data, so we'll drop these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2398795</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473747</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2254736</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>431534</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3367565</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  user_id  order_number\n",
       "1   2398795        1             2\n",
       "2    473747        1             3\n",
       "3   2254736        1             4\n",
       "4    431534        1             5\n",
       "5   3367565        1             6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_orders = orders.query('order_number > 1'\n",
    "                            )[['order_id', 'user_id', 'order_number']]\n",
    "return_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2398795</th>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398795</th>\n",
       "      <td>10258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398795</th>\n",
       "      <td>12427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398795</th>\n",
       "      <td>13176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398795</th>\n",
       "      <td>26088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          product_id  reordered\n",
       "order_id                       \n",
       "2398795          196          1\n",
       "2398795        10258          0\n",
       "2398795        12427          1\n",
       "2398795        13176          0\n",
       "2398795        26088          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_order_products = pd.merge(left=return_orders[['order_id']],\n",
    "                                 right=order_products,\n",
    "                                 on='order_id'\n",
    "                                ).set_index('order_id')\n",
    "return_order_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's stop here and clear out some tables we don't need any more, to save RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del order_products_prior\n",
    "del order_products_train\n",
    "del order_products\n",
    "del orders\n",
    "del products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to generate the order pairs for each user. This will also take a few minutes.\n",
    "\n",
    "Some of the later orders will be in the Kaggle test set, which we're not using for this project (as our objective is slightly different from the Kaggle contest). So we filter down to only ones that we have data for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>2398795</td>\n",
       "      <td>473747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>473747</td>\n",
       "      <td>2254736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2254736</td>\n",
       "      <td>431534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>431534</td>\n",
       "      <td>3367565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3367565</td>\n",
       "      <td>550135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 x        y\n",
       "user_id                    \n",
       "1       0  2398795   473747\n",
       "        1   473747  2254736\n",
       "        2  2254736   431534\n",
       "        3   431534  3367565\n",
       "        4  3367565   550135"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the itertools docs -- get consecutive pairs from a sequence\n",
    "def pairwise(iterable):\n",
    "  \"s -> (s0, s1), (s1, s2), (s2, s3), ...\"\n",
    "  a, b = tee(iterable)\n",
    "  next(b, None)\n",
    "  return izip(a, b)\n",
    "\n",
    "def make_x_y(order_ids):\n",
    "  pairs = list(pairwise(order_ids))\n",
    "  return pd.DataFrame.from_records(pairs, columns=['x', 'y'])\n",
    "\n",
    "valid = return_orders[return_orders.order_id.isin(return_order_products.index)]\n",
    "sort_cols = ['user_id', 'order_number']\n",
    "order_pairs = valid.sort_values(sort_cols).groupby(['user_id']).order_id.apply(make_x_y)\n",
    "order_pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before writing the output, we need to extract the ordered and reordered product IDs. This will take a little while.\n",
    "\n",
    "The orders and reorders sets will be converted to zero-padded arrays later, each as long as the biggest order, so we don't have to do that at training time. This is fine because there is no product ID 0. When training the model, Keras will filter out and ignore the zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = {}\n",
    "reorders = {}\n",
    "biggest_order_size = 0\n",
    "\n",
    "for order_id, group in return_order_products.groupby(\n",
    "  return_order_products.index, group_keys=False, sort=False):\n",
    "  \n",
    "  product_ids = group.product_id.unique()\n",
    "  orders[order_id] = product_ids\n",
    "  reorders[order_id] = group.product_id[group.reordered == 1].unique()\n",
    "  biggest_order_size = max(biggest_order_size, len(product_ids))\n",
    "  \n",
    "biggest_order_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some more cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del return_orders\n",
    "del valid\n",
    "del return_order_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out to disk\n",
    "\n",
    "Now create the datafile and the datasets within it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't remove h5/training_data.h5: [Errno 2] No such file or directory: 'h5/training_data.h5'\n"
     ]
    }
   ],
   "source": [
    "u8 = np.dtype('uint8')\n",
    "u16 = np.dtype('uint16')\n",
    "u32 = np.dtype('uint32')\n",
    "vu8 = h5py.special_dtype(vlen=u8)\n",
    "vu16 = h5py.special_dtype(vlen=u16)\n",
    "\n",
    "datapath = path(h5_dir, 'training_data.h5')\n",
    "\n",
    "try:\n",
    "  os.remove(datapath)\n",
    "except Exception, e:\n",
    "  print(\"Couldn't remove %s: %s\" % (datapath, str(e)))\n",
    "\n",
    "datafile = h5py.File(datapath)\n",
    "num_rows = len(order_pairs)\n",
    "orders_dataset = datafile.create_dataset('orders', (num_rows, biggest_order_size), dtype=u16)\n",
    "reorders_dataset = datafile.create_dataset('reorders', (num_rows, biggest_order_size), dtype=u16)\n",
    "users_dataset = datafile.create_dataset('users', (num_rows,), dtype=u32)\n",
    "labels_dataset = datafile.create_dataset('labels', (num_rows,), dtype=vu16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through the data and write it out. This can take at least an hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote row 0 of 2933665\n",
      "Wrote row 100000 of 2933665\n",
      "Wrote row 200000 of 2933665\n",
      "Wrote row 300000 of 2933665\n",
      "Wrote row 400000 of 2933665\n",
      "Wrote row 500000 of 2933665\n",
      "Wrote row 600000 of 2933665\n",
      "Wrote row 700000 of 2933665\n",
      "Wrote row 800000 of 2933665\n",
      "Wrote row 900000 of 2933665\n",
      "Wrote row 1000000 of 2933665\n",
      "Wrote row 1100000 of 2933665\n",
      "Wrote row 1200000 of 2933665\n",
      "Wrote row 1300000 of 2933665\n",
      "Wrote row 1400000 of 2933665\n",
      "Wrote row 1500000 of 2933665\n",
      "Wrote row 1600000 of 2933665\n",
      "Wrote row 1700000 of 2933665\n",
      "Wrote row 1800000 of 2933665\n",
      "Wrote row 1900000 of 2933665\n",
      "Wrote row 2000000 of 2933665\n",
      "Wrote row 2100000 of 2933665\n",
      "Wrote row 2200000 of 2933665\n",
      "Wrote row 2300000 of 2933665\n",
      "Wrote row 2400000 of 2933665\n",
      "Wrote row 2500000 of 2933665\n",
      "Wrote row 2600000 of 2933665\n",
      "Wrote row 2700000 of 2933665\n",
      "Wrote row 2800000 of 2933665\n",
      "Wrote row 2900000 of 2933665\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(num_rows):\n",
    "  \n",
    "  user_id = order_pairs.index[i][0]\n",
    "  \n",
    "  # The earlier of the two orders\n",
    "  order1 = order_pairs.iloc[i, 0]\n",
    "\n",
    "  # The later of the two orders, that we're trying to predict the contents of\n",
    "  order2 = order_pairs.iloc[i, 1]\n",
    "  \n",
    "  # Create padded array from order1's products\n",
    "  order1_padded = np.zeros(biggest_order_size, dtype=np.uint16)\n",
    "  order1_ids = orders[order1]\n",
    "  order1_size = len(order1_ids)\n",
    "  order1_padded[0:order1_size] = order1_ids\n",
    "  \n",
    "  # Create padded array from order1's reorders\n",
    "  reorder1_padded = np.zeros_like(order1_padded)\n",
    "  reorder1_ids = reorders[order1] if order1 in reorders else []\n",
    "  reorder1_size = len(reorder1_ids)\n",
    "  reorder1_padded[0:reorder1_size] = reorder1_ids\n",
    "\n",
    "  # Labels for each item in order1: just the IDs from order2\n",
    "  labels = orders[order2]\n",
    "  \n",
    "  # Write data out to file\n",
    "  orders_dataset[i] = order1_padded\n",
    "  reorders_dataset[i] = reorder1_padded\n",
    "  users_dataset[i] = user_id\n",
    "  labels_dataset[i] = labels\n",
    "  if i % 100000 == 0:\n",
    "    print(\"Wrote row %d of %d\" % (i, num_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can write out some scalar values that the model needs to know, and then close the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biggest_order_scalar = datafile.create_dataset('biggest_order_size', (1,), dtype=u16)\n",
    "num_rows_scalar = datafile.create_dataset('num_rows', (1,), dtype=u32)\n",
    "max_product_id_scalar = datafile.create_dataset('max_product_id', (1,), dtype=u16)\n",
    "max_user_id_scalar = datafile.create_dataset('max_user_id', (1,), dtype=u32)\n",
    "biggest_order_scalar[0] = biggest_order_size\n",
    "num_rows_scalar[0] = num_rows\n",
    "max_product_id_scalar[0] = max_product_id\n",
    "max_user_id_scalar[0] = max_user_id\n",
    "datafile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
